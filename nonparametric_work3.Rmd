---
title: "Terceiro trabalho de Estatística Não Paramétrica"
output:
  pdf_document: default
  html_document: default
  word_document: default
---
Departamento de Estatística 
---
Wesley Furriel - RA:61493
------------------------------------------------------
***
Prof. Carlos Ap. dos Santos
------------------------------------------------------
***

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RVAideMemoire)
library(stats)
library(dplyr) 
library(MASS)       
library(ppcor)
library(pgirmess)
library(reshape)
```

**Funções**
------------------------------------------------------
***

```{r}
# Teste da Mediana para k grupos
median_test_k<-function(casos,id){
dados<-cbind(id,casos)%>%as.data.frame()
dados$posicao<-ifelse(dados$casos<=median(dados$casos),1,0)
  t1<-tapply(dados$posicao,dados$id,sum)
  dados$posicao<-ifelse(dados$casos<=median(dados$casos),0,1)
  t2<-tapply(dados$posicao,dados$id,sum)
  O<-rbind(t2,t1)%>%as.data.frame()
  n<-apply(O,2,sum)
  Tc<-sum((O[1,]-O[2,])^2/n)
  if(length(t1)==2 & (O[1,1]<5 | O[1,2]<5 | O[2,1]<5 | O[2,2]>5)) {
          fis<-fisher.test(O)
          valorp<-fis$p.value
          X2<-fis$estimate}else{
               X2<-qchisq(0.95,df = length(t1)-1)
               valorp<-pchisq(Tc,df = length(t1)-1,lower.tail = F)}
        teste<-"Median Test K-sample"
        print("Tabela de contingência")
        print(O)
        cat("\n")
        print(teste)
        cat("\n")
        result<-paste("T =",Tc,"  vs  ","X² =",X2," |  " ,
        "Valor=p =",round(valorp,10),sep = " ")
result<-paste("T =",Tc,"  vs  ","X² =",X2," |  " ,
              "Valor=p =",valorp,sep = " ")
return(result)}
```

```{r}
#U de Mann-Whitney

MannWhitney<-function(x,y){
n1<-length(x)
n2<-length(y)
  dados<-qpcR:::cbind.na(x,y) 
  df<-melt(dados)
  df2<-subset(df,df$value != "NA")
  df2<-df2[order(df2$value),]
  df2$posto<-seq(1:length(df2$value))
    R<-tapply(df2$posto,df2$X2,sum)
    R1<-R[1]%>%as.numeric()
    R2<-R[2]%>%as.numeric()
    U1<-n1*n2 + (n1*(n1+1))/2 - R1
    U2<-n1*n2 + (n2*(n2+1))/2 - R2
    U<-ifelse(U1 < U2,U1,U1)
      if(n1 > 20 | n2 > 20){
        mu<-(n1*n2)/2
        sigma<-sqrt(((n1*n2)*((n1+n2+1)))/12)
        z<-(U-mu)/sigma
        valorp<-pnorm(q = z,mean = mu,sd = sigma)
        print("U de MANN - WHITNEY")
        cat("\n")    
        resultado<-paste("Z =",z," | ","valor-p =",valorp," | ","n1 =",n1," | ",
                         "n2 =",n2, sep = " ")
        return(resultado)}
        else{
            print("Verificar na tabela U de MANN - WHITNEY")
            cat("\n")    
            resultado<-paste("U =",U," | ","n1 =",n1," | ", "n2 =",n2, sep = " ")
            return(resultado)}}
```
Não é possível rejeitar $H_0$ para o teste KS, porém, para U de Mann-Whitney rejeitamos.


**Lista 2**
------------------------------------------------------
***

**Exercício 1.2**
------------------------------------------------------
***

- Teste Exato de Fisher

$H_0$: As categorias são iguais

$H_1$: As categorias diferem

Como temos uma tabela de contingência 2x2, para comparar 2 grupos, sendo n < 20 
nesse caso usaremos fisher.

```{r}
tabela <- matrix(c(2, 3, 5, 2),
          nrow = 2,
          dimnames =
           list(c("Sim", "Não"),
                c("A", "B")))
tabela
fisher.test(tabela)
```

Verificando os resultados rejeitamos $H_0$, desse modo, A e B são diferentes

**Exercício 2.2**
------------------------------------------------------
***

- Teste de Wilcoxon ou U de Mann Whitney não pareado

$H_0$: As medianas são iguais

$H_1$: As medianas diferem

```{r}
h1<-c(34, 16, 12, 4, 2)
h2<-c(12, 6, 6, 4, 0)
wilcox.test(h1, h2, paired=F) 
```

Não é possível rejeitar $H_0$, assim, os hospitais não diferem.

**Exercício 3.2**
------------------------------------------------------
***

- Teste Exato de Fisher

$H_0$: As categorias são iguais

$H_1$: As categorias diferem

Como temos uma tabela de contingência 2x2, para comparar 2 grupos, sendo n < 20 
nesse caso usaremos fisher.

```{r}
# Entrada por coluna
tabela <- matrix(c(3, 4, 7, 1),
          nrow = 2,
          dimnames =
           list(c("A", "B"),
                c("Fecundos", "NFecundos")))
tabela
fisher.test(tabela)
```

Não é possível rejeitar $H_0$, desse modo não há relação entre as variáveis.

**Exercício 4.2**
------------------------------------------------------
***

- Teste de Wilcoxon ou U de Mann Whitney não pareado

$H_0$: As medianas são iguais

$H_1$: As medianas diferem

```{r}
wd<-"D:/Estatística/Nonparametric Statistical/TRABALHO 3"
setwd(wd)
dados<-read.table("banco1.txt", sep=";", header = T, dec=".")
x1931<-dados$y1931
x1932<-dados$y1932

wilcox.test(x1931, x1932, paired=F) 

```

Rejeita-se $H_0$, de modo que constatamos a diferença entre as medianas dos dois anos.

**Exercício 5.2**
------------------------------------------------------
***

- Teste da mediana para dois grupos de tamanhos distintos

$H_0$: As medianas são iguais

$H_1$: As medianas diferem

```{r}
RH<-c(15,12,13,18,9,11,12,13,14,14,12,12,11,10)
CQ<-c(8,7,14,10,8,6,7,6,8,4)

casos<-c(RH,CQ)
id<-c(rep(1,length(RH)),rep(2,length(CQ)))%>%as.factor()

median_test_k(casos,id)
```

Através do p-valor rejeitamos $H_0$, ou seja, com 95% de confiança há
evidência amostral de que os escores de inteligência emocional dos dois
setores não provem de populações com a mesma mediana.

**Exercício 6.2**
------------------------------------------------------
***

- Teste da mediana para dois grupos de tamanhos distintos

$H_0$: As medianas são iguais

$H_1$: As medianas diferem

```{r}
A<-c(4.3,2.2,3.8,1.8,5.2,4.5,2.5,1.7,3.5,3.6,4.1,4.5,5.1,5.0,4.0,5.1)
B<-c(4.2,6.2,4.8,6.8,4.7,6.5,6.3,5.9,7.2)

casos<-c(A,B)
id<-c(rep(1,length(A)),rep(2,length(B)))%>%as.factor()

median_test_k(casos,id)
```
Rejeitamos $H_0$ com 95% de confiança, dessa forma, A e B diferem na produtividade.

**Exercício 7.2**
------------------------------------------------------
***

- Teste KS

$H_0$: Não existem diferenças entre os grupos

$H_1$: Existem diferenças entre os grupos

Sendo os dados agrupados ou ordinais faremos o teste KS

```{r}
A<-c(10, 28, 2, 1, 1)
B<-c(6, 55, 6, 0, 0)
ks.test(A,B)	
```
Não existem evidências para rejeitar $H_0$. Assim, não se pode afirmar que existe diferença significativa entre o desempenho dos dois grupos de estudantes.

**Exercício 8.2**
------------------------------------------------------
***

- Teste KS

$H_0$: Não existem diferenças entre os grupos

$H_1$: Existem diferenças entre os grupos

Sendo os dados agrupados ou ordinais faremos o teste KS

```{r}
x<-c(26, 65, 8, 1)
y<-c(55, 40, 2, 3)
ks.test(x,y)	
```

Não existem evidências para rejeitar $H_0$. Assim, não se pode afirmar que existe diferença significativa entre os dois grupos

**Exercício 11.2**
------------------------------------------------------
***

- Teste KS e Mann-Whitney U-test

$H_0$: Não existem diferenças entre os grupos

$H_1$: Existem diferenças entre os grupos

```{r}
bul<-c(15.9,18.9,25.1,16.0,19.6,25.2,16.5,21.5,25.6,17.0,21.6,
28.0,17.6,22.9,28.7,18.1,23.6,29.2,18.4,24.1,30.9,18.9,
24.5,30.6)
sau<-c(20.7,30.6,22.4,33.2,23.1,33.7,23.8,36.6,
24.5,37.1,25.3,37.4,25.7,40.8)

ks.test(bul,sau)

MannWhitney(bul,sau)

```

Não é possível rejeitar $H_0$. Assim, não se pode afirmar que existe diferença significativa entre os grupos.

---------------------------------------------------------------------------------

**Lista 3**
------------------------------------------------------
***

**Exercício 1.3**
------------------------------------------------------
***

- Teste de Cochran

$H_0$: Os métodos de explicação são iguais

$H_1$: Pelo menos um método difere

```{r}
result<-c(1,1,1,0,1,0,0,1,0,0,1,0,0,1,1,0,0,0,0,1,0,1,1,0,1,1,1,0,0,0,
          0,0,0,0,1,0,0,1,0,0,1,1,0,1,0,1,1,0,1,1,1,0,1,0)
nlinha<-18
ncol<-3  

blocos<-factor(rep(letters[1:ncol],nlinha))
estudantes<-factor(rep(letters[1:nlinha], each=ncol))
tapply(result, list(estudantes,blocos), sum)
cochran.qtest(result~blocos|estudantes)
```

Rejeita-se H0 à 5% de sig, ou seja, existe diferença entre os métodos de explicação empregados pelo professor

**Exercício 2.3**
------------------------------------------------------
***

- Friedman e Quade

$H_0$: Não existe diferença entre os tratamentos

$H_1$: Existe diferença entre os tratamentos

```{r}
nlinha<-4
dados<-matrix(c(3640, 4200, 4700, 5300,
                4890, 4550, 6020, 5900,
                4800, 5320, 5250, 5150,
                4460, 5500, 5580, 5560),
              nrow = nlinha,
              byrow = TRUE,
              dimnames = list(1 : nlinha,
                              c("Trat.1","Trat.2","Trat.3","Trat.4")))
friedman.test(dados)
quade.test(dados)
```
Os testes apresentaram conclusões distintas. Desse modo, para o teste de Friedman não há diferenças entre os tratamentos, assim, não rejeitamos $H_0$. Porém, para o teste de Quade rejeitamos, de modo, que há diferença em pelo menos um dos tratamentos. 

**Exercício 3.3**
------------------------------------------------------
***

- Friedman e Quade

$H_0$: Não existe diferença entre os tratamentos

$H_1$: Existe diferença entre os tratamentos

```{r}
nlinha<-10
N<-0
R<-1
B<-2
O<-3
dados<-
  matrix(c(B, B, O, O,
                R, O, O, O,
                O, O, R, B,
                R, N, O, O,
                O, N, R, B,
                R, O, N, O,
                B, R, O, O,
                N, R, B, O,
                R, O, B, B,
                B, R, N, O),
              nrow = nlinha,
              byrow = TRUE,
              dimnames = list(1 : nlinha,
                              c("Trat.1","Trat.2","Trat.3","Trat.4")))
friedman.test(dados)
quade.test(dados)
```

Não rejeitamos $H_0$ para ambos os testes. Assim, não ocorretam diferenças nas avaliações dos degustadores. 


**Exercício 4.3**
------------------------------------------------------
***
- Teste da Mediana

$H_0$: As medianas são iguais

$H_1$: As medianas são diferentes

```{r}
casos<-c(8,7,14,10,8,6,7,6,8,4, 
         2,4,6,14,10,8,6,2,2,3,4,6,8,
         5,4,8,12,3,10,4,14,11,10,8,12,10,10,9,8,8,9,8,7,11,
         15,12,13,8,9,11,12,13,14,14,12,12,11,10,14,12)
id<-c(rep(1,10),rep(2,16),rep(3,18),rep(4,16))

median_test_k(casos,id)

```
Rejeitamos $H_0$, desse modo, há diferenças entre as medianas.

**Exercício 5.3**
------------------------------------------------------
***

- Teste da Mediana e Kruskal-Wallis

$H_0$: As medianas são iguais

$H_1$: Pelo menos uma mediana é diferente

```{r}

casos<-c(45.8,43.3,48.1,46,47.2,47.6,47.9,45.4,43.0,42.4,40.9,44.2,43.0,39.1,42.1,
         44.5,52.7,54.2,49.4,44.8,50.0,44.2,51.8,50.6,43.9,44.5,50.3)
id<-c(rep(1,5),rep(2,5),rep(3,5),rep(4,6),rep(5,6))

median_test_k(casos,id)

id<-id%>%as.factor()

kruskal.test(casos, id)
```

Não rejeitamos $H_0$ pelo teste da mediana, ou seja, as medianas são iguais, as marcas de pneus tem a mesma frenagem. Entretanto pelo Kruskal-Wallis rejeitamos a hipótese nula, tendo a conclusão contrária.

**Exercício 6.3**
------------------------------------------------------
***

- Kruskal-Wallis

$H_0$: Os tratamentos são iguais

$H_1$: Pelo menos um tratamento é diferente

```{r}
casos<-c(13.03,11.66,13.86,12.22,14.16,14.69,15.67,15.91,15.68,
         13.22,11.54,13.08,14.07,14.23,14.98,16.59,16.38,15.74,
         13.30,12.08,13.22,13.51,14.26,14.95,15.19,17.07,15.95,
      	 13.20,10.86,13.34,13.09,15.22,14.69,15.63,16.58,16.54,
         13.19,13.05,13.93,13.13,13.84,14.75,15.48,16.82,16.12,
	       12.70,11.95,12.82,13.27,14.39,14.54,15.42,15.77,16.02)
id<-sort(c(rep(1:6,9)))%>%as.factor();id

kruskal.test(casos, id)

# Comparação múltipla
kruskalmc(casos, id)
```
Não rejeitamos $H_0$ ao nível de significância de 5%, ou seja, não há diferença entre os tratamentos. 

Realizando as comparações múltiplas confirmamos a não diferença entre os tratamentos.

**Exercício 7.3**
------------------------------------------------------
***

- Qui-quadrado

$H_0$: A preferência não muda segundo o filme

$H_1$: A preferência muda

```{r}
sol<-c(45, 25, 30)
cas<-c(36, 61, 43)
div<- c(39, 36, 35)
viu<-c(14, 19, 17)
tbl<-rbind(sol,cas,div,viu)%>%as.data.frame()
names(tbl)<-c("Pol", "Com", "Rom")                 
tbl          
          
chisq.test(tbl) 

```

Partindo dos resultados rejeitamos $H_0$, dessa forma, a preferência por determinado gênero de filmes muda segundo o estado civil.

**Exercício 8.3**
------------------------------------------------------
***

- Rho de Spearman e Kendall

$H_0$: Não relação entre as variáveis

$H_1$: Há relação entre as variáveis

```{r}
x <- c(5, 9, 17, 1, 2, 21, 3, 29, 7, 100)
y <- c(6, 16, 18, 1, 3, 21, 7, 20, 15, 22)
cor.test(x, y, method="spearman")
cor.test(x, y, method="kendall")
```

Como é possível observar ambos os testes são significativos ao nível de 5%. Além disso, constatamos correlações altas, maiores que 90%. No caso do Rho de Spearman praticamente uma correlação perfeita, próxima a 1.

**Exercício 9.3**
------------------------------------------------------
***

- Rho de Spearman e Kendall

$H_0$: Não relação entre as variáveis

$H_1$: Há relação entre as variáveis

```{r}
x <- c(107, 96, 103, 89, 96, 113, 86, 99, 109, 105, 96, 89)
y <- c(111, 97, 116, 107, 99, 111, 85, 108, 102, 105, 100, 97)
cor.test(x, y, method="spearman")
cor.test(x, y, method="kendall")
```

Como é possível observar ambos os testes são significativos ao nível de 5%. Além disso, constatamos correlações moderadas próximas a 50%.

**Exercício 10.3**
------------------------------------------------------
***

- Rho de Spearman e Kendall parcial

$H_0$: Não relação entre as variáveis

$H_1$: Há relação entre as variáveis

```{r}
x<-c(60, 54, 59, 65, 55, 71, 57, 77, 63, 54, 63)
y<-c(62, 54, 65, 66, 63, 74, 58, 76, 65, 59, 62)
z<-c(64, 50, 71, 68, 61, 76, 63, 79, 70, 62, 64)
pcor.test(x, y ,z ,method = "spearman")
pcor.test(x, y ,z ,method = "kendall")
```

No que tange a correlação parcial os efeitos de uma terceira variável Z sobre as
variáveis X e Y são controlados mantendo-a constante. Desse modo, verificamos que os valores de X e Y quando controlados por Z não tem correlação, tanto pelo teste de Kendall quanto pelo de Spearman. 

**Exercício 11.3**
------------------------------------------------------
***

- Kruskal-Wallis

$H_0$: Os tratamentos são iguais

$H_1$: Pelo menos um tratamento é diferente

```{r}
casos<-c(23.46,23.48,23.56,23.39,23.40,
         23.59,23.46,23.42,23.49,23.50,
         23.51,23.64,23.46,23.52,23.49,
         23.28,23.40,23.37,23.46,23.39,
         23.29,23.46,23.37,23.32,23.38)

id<-sort(c(rep(1:5,5)))%>%as.factor();id

kruskal.test(casos, id)

# Comparação múltipla
kruskalmc(casos, id)
```

Análisando os resultados constatamos que pelo menos um dos tratamentos diferem, ou seja, rejeitamos $H_0$. Pelo teste de comparação múltiplas concluimos que o tratamento 3 e 5 diferem, os demais são consideramos iguais.

**Exercício 12.3**
------------------------------------------------------
***

- Qui-quadrado

$H_0$: Não há relação entre nível de hemoglobina e grupos étnicos

$H_1$: Há relação entre nível de hemoglobina e grupos étnicos

```{r}
A<-c(80, 100, 20)
B<-c(99, 190, 96)
C<- c(70, 39, 10)
tbl<-rbind(A,B,C)%>%as.data.frame()
names(tbl)<-c("h10", "h9_9.9", "h9")                 
tbl          
          
chisq.test(tbl) 

```
Rejeitamos $H_0$ com folga, sendo valor-p <0.0001, desse modo existêm evidências amostrais de que grupo étnico e o nível de hemoglobina estão associados.

